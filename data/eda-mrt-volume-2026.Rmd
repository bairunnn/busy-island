---
title: "eda-mrt-volume-2025-07-17"
author: "bh"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sf)
library(ggplot2)
library(dplyr)
library(readxl)
library(tidyr)
library(stringr)
library(purrr)

```

## MRT Map

Check for mrt map coverage

```{r mrtt}
mrt_lines <- st_read("MRTLines_20241113_future.geojson")
```

```{r mrtt-map}
ggplot(mrt_lines) +
  geom_sf(aes(color = colour), size = 1) +
  scale_color_identity() +  # Use color codes as-is
  theme_void()
```

## MRT Stations

Stations

```{r mrt-stations}
mrt_stations <- st_read("MRTStations_20240914_v1.geojson")
```

```{r}
ggplot(mrt_stations) +
  geom_sf(color = "black", size = 1) +
  theme_void()
```

## Cleaning stations file

```{r}

mrt_stations_cleaned <- mrt_stations

names(mrt_stations_cleaned)

mrt_stations_cleaned <- mrt_stations %>%
  rename(
    station_codes = ref,
    line_names = network
  ) %>%
  select(station_codes, line_names, name, geometry)

```

### Other LTA datasets

#### MRT station polygons

```{r}
mrt_list1 <- st_read("./TrainStation_Apr2025/RapidTransitSystemStation.shp")
```

#### MRT codes

```{r}
mrt_codes <- read_excel("Train Station Codes and Chinese Names.xls")
```

```{r}
mrt_codes_condensed <- mrt_codes %>%
  select(station_name = mrt_station_english, code = stn_code) %>%
  group_by(station_name) %>%
  mutate(code_rank = paste0("code", row_number())) %>%
  pivot_wider(
    names_from = code_rank,
    values_from = code
  ) %>%
  ungroup()
```

```{r}
mrt_stations_joined <- mrt_stations_cleaned %>%
  left_join(mrt_codes_condensed, by = c("name" = "station_name")) %>% 
  select(-c(station_codes, line_names))
```

```{r}
ggplot(mrt_stations_joined) +
  geom_sf(color = "darkblue", size = 1) +
  theme_void()
```

### Fix future stations

```{r}
mrt_stations_joined %>%
  filter(is.na(code1)) %>%
  pull(name) %>%
  print()
```

### Write MRT stations file

```{r}
st_write(
  mrt_stations_joined,
  "MRT_stations_with_codes_20250717.geojson",
  driver = "GeoJSON",
  delete_dsn = TRUE  # overwrite if file exists
)
```

# Volumes

Data source:

<https://datamall2.mytransport.sg/ltaodataservice/PV/Train>

postman.co

```{r}
volume_raw <- read.csv("transport_node_train_202601.csv", stringsAsFactors = FALSE)

str(volume_raw)

volume_raw <- volume_raw %>%
  select(-YEAR_MONTH, -PT_TYPE) %>%
  mutate(TIME_PER_HOUR = as.character(TIME_PER_HOUR))
```

### Reformat certain variables

```{r}
volume_raw <- volume_raw %>%
  mutate(TIME_PER_HOUR = str_pad(TIME_PER_HOUR, width = 2, side = "left", pad = "0"))

```

### Verify if data is proper

#### Verify \# of observations per station

```{r}
pt_code_counts <- volume_raw %>%
  count(PT_CODE) %>%
  arrange(n)

all_same <- n_distinct(pt_code_counts$n) == 1
print(all_same)
# If false, some stations have fewer counts than the rest

```

```{r}
# print(pt_code_counts)
```

#### Fix duplicate stations like Stevens

```{r}
dt10_te11 <- volume_raw %>%
  filter(PT_CODE %in% c("DT10", "TE11")) %>%
  group_by(DAY_TYPE, TIME_PER_HOUR) %>%
  summarise(
    PT_CODE              = "DT10/TE11",
    TOTAL_TAP_IN_VOLUME  = sum(TOTAL_TAP_IN_VOLUME, na.rm = TRUE),
    TOTAL_TAP_OUT_VOLUME = sum(TOTAL_TAP_OUT_VOLUME, na.rm = TRUE),
    .groups = "drop"
  )

volume_raw <- volume_raw %>%
  filter(!PT_CODE %in% c("DT10", "TE11")) %>%
  bind_rows(dt10_te11)
```

### Join station names

```{r}
volume_processed <- volume_raw
volume_processed <- volume_processed %>%
  separate(
    col = PT_CODE,
    into = c("PT_CODE_1", "PT_CODE_2", "PT_CODE_3"),
    sep = "/",
    fill = "right"  # fill missing values with NA
  )
```

```{r}
volume_processed$stn_name <- NA_character_

# Define lookup function
get_station_name <- function(code) {
  match_row <- mrt_stations_joined %>%
    filter(code1 == code | code2 == code | code3 == code) %>%
    slice(1)  # take first match only
  if (nrow(match_row) == 0) {
    return(NA_character_)
  } else {
    return(match_row$name)
  }
}

# Apply function row-wise
volume_processed <- volume_processed %>%
  mutate(stn_name = map_chr(PT_CODE_1, get_station_name))

```

### Mutate lines

c(EWL, NSL, NEL, CCL, DTL, PGLRT, SKLRT, BPLRT, TEL)

```{r}
volume_processed <- volume_processed %>%
  mutate(
    EWL   = if_else(if_any(c(PT_CODE_1, PT_CODE_2, PT_CODE_3), ~ str_detect(.x, "EW|CG")), 1, 0),
    NSL   = if_else(if_any(c(PT_CODE_1, PT_CODE_2, PT_CODE_3), ~ str_detect(.x, "NS")), 1, 0),
    NEL   = if_else(if_any(c(PT_CODE_1, PT_CODE_2, PT_CODE_3), ~ str_detect(.x, "NE")), 1, 0),
    CCL   = if_else(if_any(c(PT_CODE_1, PT_CODE_2, PT_CODE_3), ~ str_detect(.x, "CC|CE")), 1, 0),
    DTL   = if_else(if_any(c(PT_CODE_1, PT_CODE_2, PT_CODE_3), ~ str_detect(.x, "DT")), 1, 0),
    PGLRT = if_else(if_any(c(PT_CODE_1, PT_CODE_2, PT_CODE_3), ~ str_detect(.x, "PW|PE")), 1, 0),
    SKLRT = if_else(if_any(c(PT_CODE_1, PT_CODE_2, PT_CODE_3), ~ str_detect(.x, "SW|SE")), 1, 0),
    BPLRT = if_else(if_any(c(PT_CODE_1, PT_CODE_2, PT_CODE_3), ~ str_detect(.x, "BP")), 1, 0),
    TEL   = if_else(if_any(c(PT_CODE_1, PT_CODE_2, PT_CODE_3), ~ str_detect(.x, "TE")), 1, 0)
  ) %>%
  mutate(
    across(
      c(EWL, NSL, NEL, CCL, DTL, PGLRT, SKLRT, BPLRT, TEL),
      ~ replace_na(.x, 0)
    )
  )
```

### Check number of stations (overall & per line)

```{r}
n_distinct(volume_processed$stn_name)

```

```{r}
summary_stn_counts <- volume_processed %>%
  summarise(
    across(
      c(EWL, NSL, NEL, CCL, DTL, PGLRT, SKLRT, BPLRT, TEL),
      ~ n_distinct(stn_name[.x == 1])
    )
  )

summary_stn_counts
```

### Weekday volumes

```{r}
volume_weekdays <- volume_processed %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  select(-DAY_TYPE)

summary_weekdays <- volume_weekdays %>%
  group_by(stn_name, EWL, NSL, NEL, CCL, DTL, PGLRT, SKLRT, BPLRT, TEL) %>%
  summarise(
    total_in  = sum(TOTAL_TAP_IN_VOLUME, na.rm = TRUE),
    total_out = sum(TOTAL_TAP_OUT_VOLUME, na.rm = TRUE),
    total_sum = total_in + total_out,
    .groups = "drop"
  )

n_distinct(summary_weekdays$stn_name)

write.csv(summary_weekdays, "summary_weekdays.csv")
```

#### AM peak - 09 10

```{r}
volume_weekdays_am_peak <- volume_weekdays %>%
  filter(TIME_PER_HOUR %in% c("08", "09"))

summary_weekdays_am_peak <- volume_weekdays_am_peak %>%
  group_by(stn_name, EWL, NSL, NEL, CCL, DTL, PGLRT, SKLRT, BPLRT, TEL) %>%
  summarise(
    total_in  = sum(TOTAL_TAP_IN_VOLUME, na.rm = TRUE),
    total_out = sum(TOTAL_TAP_OUT_VOLUME, na.rm = TRUE),
    total_sum = total_in + total_out,
    .groups = "drop"
  )
n_distinct(summary_weekdays_am_peak$stn_name)
write.csv(summary_weekdays_am_peak, "summary_weekdays_am_peak.csv")

```

#### PM peak - 17 18 19

```{r}
volume_weekdays_pm_peak <- volume_weekdays %>%
  filter(TIME_PER_HOUR %in% c("17", "18", "19"))

summary_weekdays_pm_peak <- volume_weekdays_pm_peak %>%
  group_by(stn_name, EWL, NSL, NEL, CCL, DTL, PGLRT, SKLRT, BPLRT, TEL) %>%
  summarise(
    total_in  = sum(TOTAL_TAP_IN_VOLUME, na.rm = TRUE),
    total_out = sum(TOTAL_TAP_OUT_VOLUME, na.rm = TRUE),
    total_sum = total_in + total_out,
    .groups = "drop"
  )
n_distinct(summary_weekdays_pm_peak$stn_name)
write.csv(summary_weekdays_pm_peak, "summary_weekdays_pm_peak.csv")
```

### Weekend volumes

```{r}
volume_weekends <- volume_processed %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  select(-DAY_TYPE)

summary_weekends <- volume_weekends %>%
  group_by(stn_name, EWL, NSL, NEL, CCL, DTL, PGLRT, SKLRT, BPLRT, TEL) %>%
  summarise(
    total_in  = sum(TOTAL_TAP_IN_VOLUME, na.rm = TRUE),
    total_out = sum(TOTAL_TAP_OUT_VOLUME, na.rm = TRUE),
    total_sum = total_in + total_out,
    .groups = "drop"
  )
n_distinct(summary_weekends$stn_name)
write.csv(summary_weekends, "summary_weekends.csv")
```
